{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple KubeFlow Pipeline\n",
    "\n",
    "Lightweight python components do not require you to build a new container image for every code change.\n",
    "They're intended to use for fast iteration in notebook environment.\n",
    "\n",
    "#### Building a lightweight python component\n",
    "To build a component just define a stand-alone python function and then call kfp.components.func_to_container_op(func) to convert it to a component that can be used in a pipeline.\n",
    "\n",
    "There are several requirements for the function:\n",
    "* The function should be stand-alone. It should not use any code declared outside of the function definition. Any imports should be added inside the main function. Any helper functions should also be defined inside the main function.\n",
    "* The function can only import packages that are available in the base image. If you need to import a package that's not available you can try to find a container image that already includes the required packages. (As a workaround you can use the module subprocess to run pip install for the required package.)\n",
    "* If the function operates on numbers, the parameters need to have type hints. Supported types are ```[int, float, bool]```. Everything else is passed as string.\n",
    "* To build a component with multiple output values, use the typing.NamedTuple type hint syntax: ```NamedTuple('MyFunctionOutputs', [('output_name_1', type), ('output_name_2', float)])```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple function that just add two numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a Python function\n",
    "def add_fn(a: float, b: float) -> float:\n",
    "   '''Calculates sum of two arguments'''\n",
    "   return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the function to a pipeline operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.components as comp\n",
    "\n",
    "add_op = comp.func_to_container_op(add_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit more advanced function which demonstrates how to use imports, helper functions and produce multiple outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "def div_fn(dividend: float, divisor:float, output_dir:str = './') -> NamedTuple('DivOutput', [('quotient', float), ('remainder', float)]):\n",
    "    '''Divides two numbers and calculate  the quotient and remainder'''\n",
    "    #Imports inside a component function:\n",
    "    import numpy as np\n",
    "\n",
    "    #This function demonstrates how to use nested functions inside a component function:\n",
    "    def nested_div_helper(dividend, divisor):\n",
    "        return np.divmod(dividend, divisor)\n",
    "\n",
    "    (quotient, remainder) = nested_div_helper(dividend, divisor)\n",
    "\n",
    "    from tensorflow.python.lib.io import file_io\n",
    "    import json\n",
    "    \n",
    "    # Exports two sample metrics:\n",
    "    metrics = {\n",
    "      'metrics': [{\n",
    "          'name': 'quotient',\n",
    "          'numberValue':  float(quotient),\n",
    "        },{\n",
    "          'name': 'remainder',\n",
    "          'numberValue':  float(remainder),\n",
    "        }]}\n",
    "\n",
    "    with file_io.FileIO(output_dir + 'mlpipeline-metrics.json', 'w') as f:\n",
    "        json.dump(metrics, f)\n",
    "\n",
    "    from collections import namedtuple\n",
    "    output = namedtuple('DivOutput', ['quotient', 'remainder'])\n",
    "    return output(quotient, remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test running the python function directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DivOutput(quotient=14, remainder=2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_fn(100, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the function to a pipeline operation\n",
    "\n",
    "You can specify an alternative base container image (the image needs to have Python 3.5+ installed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_op = comp.func_to_container_op(div_fn, base_image='tensorflow/tensorflow:1.13.1-py3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the pipeline\n",
    "Pipeline function has to be decorated with the `@dsl.pipeline` decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.dsl as dsl\n",
    "@dsl.pipeline(\n",
    "   name='Calculation pipeline',\n",
    "   description='A toy pipeline that performs arithmetic calculations.'\n",
    ")\n",
    "def add_div_pipeline(\n",
    "   a='a',\n",
    "   b='7',\n",
    "   c='17',\n",
    "):\n",
    "    #Passing pipeline parameter and a constant value as operation arguments\n",
    "    add_task = add_op(a, 4) #Returns a dsl.ContainerOp class instance. \n",
    "    \n",
    "    #Passing a task output reference as operation arguments\n",
    "    #For an operation with a single return value, the output reference can be accessed using `task.output` or `task.outputs['output_name']` syntax\n",
    "    div_task = div_op(add_task.output, b, '/')\n",
    "\n",
    "    #For an operation with a multiple return values, the output references can be accessed using `task.outputs['output_name']` syntax\n",
    "    result_task = add_op(div_task.outputs['quotient'], c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_func = add_div_pipeline\n",
    "pipeline_filename = pipeline_func.__name__ + '.pipeline.tar.gz'\n",
    "import kfp.compiler as compiler\n",
    "compiler.Compiler().compile(pipeline_func, pipeline_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline.yaml\r\n"
     ]
    }
   ],
   "source": [
    "!tar -xvzf add_div_pipeline.pipeline.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: argoproj.io/v1alpha1\r\n",
      "kind: Workflow\r\n",
      "metadata:\r\n",
      "  generateName: calculation-pipeline-\r\n",
      "spec:\r\n",
      "  arguments:\r\n",
      "    parameters:\r\n",
      "    - name: a\r\n",
      "      value: a\r\n",
      "    - name: b\r\n",
      "      value: '7'\r\n",
      "    - name: c\r\n",
      "      value: '17'\r\n",
      "  entrypoint: calculation-pipeline\r\n",
      "  serviceAccountName: pipeline-runner\r\n",
      "  templates:\r\n",
      "  - container:\r\n",
      "      args:\r\n",
      "      - '{{inputs.parameters.a}}'\r\n",
      "      - '4'\r\n",
      "      - /outputs/Output/data\r\n",
      "      command:\r\n",
      "      - python3\r\n",
      "      - -c\r\n",
      "      - \"def add_fn(a: float, b: float) -> float:\\n   '''Calculates sum of two arguments'''\\n\\\r\n",
      "        \\   return a + b\\n\\nimport sys\\n_args = {\\n    'a': float(sys.argv[1]),\\n\\\r\n",
      "        \\    'b': float(sys.argv[2]),\\n}\\n_output_files = [\\n    sys.argv[3],\\n]\\n\\\r\n",
      "        \\n_outputs = add_fn(**_args)\\n\\nif not hasattr(_outputs, '__getitem__') or\\\r\n",
      "        \\ isinstance(_outputs, str):\\n    _outputs = [_outputs]\\n\\nfrom pathlib import\\\r\n",
      "        \\ Path\\nfor idx, filename in enumerate(_output_files):\\n    _output_path =\\\r\n",
      "        \\ Path(filename)\\n    _output_path.parent.mkdir(parents=True, exist_ok=True)\\n\\\r\n",
      "        \\    _output_path.write_text(str(_outputs[idx]))\\n\"\r\n",
      "      image: tensorflow/tensorflow:1.11.0-py3\r\n",
      "    inputs:\r\n",
      "      parameters:\r\n",
      "      - name: a\r\n",
      "    name: add-fn\r\n",
      "    outputs:\r\n",
      "      artifacts:\r\n",
      "      - name: mlpipeline-ui-metadata\r\n",
      "        path: /mlpipeline-ui-metadata.json\r\n",
      "        s3:\r\n",
      "          accessKeySecret:\r\n",
      "            key: accesskey\r\n",
      "            name: mlpipeline-minio-artifact\r\n",
      "          bucket: mlpipeline\r\n",
      "          endpoint: minio-service.kubeflow:9000\r\n",
      "          insecure: true\r\n",
      "          key: runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-ui-metadata.tgz\r\n",
      "          secretKeySecret:\r\n",
      "            key: secretkey\r\n",
      "            name: mlpipeline-minio-artifact\r\n",
      "      - name: mlpipeline-metrics\r\n",
      "        path: /mlpipeline-metrics.json\r\n",
      "        s3:\r\n",
      "          accessKeySecret:\r\n",
      "            key: accesskey\r\n",
      "            name: mlpipeline-minio-artifact\r\n",
      "          bucket: mlpipeline\r\n",
      "          endpoint: minio-service.kubeflow:9000\r\n",
      "          insecure: true\r\n",
      "          key: runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-metrics.tgz\r\n",
      "          secretKeySecret:\r\n",
      "            key: secretkey\r\n",
      "            name: mlpipeline-minio-artifact\r\n",
      "      parameters:\r\n",
      "      - name: add-fn-output\r\n",
      "        valueFrom:\r\n",
      "          path: /outputs/Output/data\r\n",
      "  - container:\r\n",
      "      args:\r\n",
      "      - '{{inputs.parameters.div-fn-quotient}}'\r\n",
      "      - '{{inputs.parameters.c}}'\r\n",
      "      - /outputs/Output/data\r\n",
      "      command:\r\n",
      "      - python3\r\n",
      "      - -c\r\n",
      "      - \"def add_fn(a: float, b: float) -> float:\\n   '''Calculates sum of two arguments'''\\n\\\r\n",
      "        \\   return a + b\\n\\nimport sys\\n_args = {\\n    'a': float(sys.argv[1]),\\n\\\r\n",
      "        \\    'b': float(sys.argv[2]),\\n}\\n_output_files = [\\n    sys.argv[3],\\n]\\n\\\r\n",
      "        \\n_outputs = add_fn(**_args)\\n\\nif not hasattr(_outputs, '__getitem__') or\\\r\n",
      "        \\ isinstance(_outputs, str):\\n    _outputs = [_outputs]\\n\\nfrom pathlib import\\\r\n",
      "        \\ Path\\nfor idx, filename in enumerate(_output_files):\\n    _output_path =\\\r\n",
      "        \\ Path(filename)\\n    _output_path.parent.mkdir(parents=True, exist_ok=True)\\n\\\r\n",
      "        \\    _output_path.write_text(str(_outputs[idx]))\\n\"\r\n",
      "      image: tensorflow/tensorflow:1.11.0-py3\r\n",
      "    inputs:\r\n",
      "      parameters:\r\n",
      "      - name: c\r\n",
      "      - name: div-fn-quotient\r\n",
      "    name: add-fn-2\r\n",
      "    outputs:\r\n",
      "      artifacts:\r\n",
      "      - name: mlpipeline-ui-metadata\r\n",
      "        path: /mlpipeline-ui-metadata.json\r\n",
      "        s3:\r\n",
      "          accessKeySecret:\r\n",
      "            key: accesskey\r\n",
      "            name: mlpipeline-minio-artifact\r\n",
      "          bucket: mlpipeline\r\n",
      "          endpoint: minio-service.kubeflow:9000\r\n",
      "          insecure: true\r\n",
      "          key: runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-ui-metadata.tgz\r\n",
      "          secretKeySecret:\r\n",
      "            key: secretkey\r\n",
      "            name: mlpipeline-minio-artifact\r\n",
      "      - name: mlpipeline-metrics\r\n",
      "        path: /mlpipeline-metrics.json\r\n",
      "        s3:\r\n",
      "          accessKeySecret:\r\n",
      "            key: accesskey\r\n",
      "            name: mlpipeline-minio-artifact\r\n",
      "          bucket: mlpipeline\r\n",
      "          endpoint: minio-service.kubeflow:9000\r\n",
      "          insecure: true\r\n",
      "          key: runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-metrics.tgz\r\n",
      "          secretKeySecret:\r\n",
      "            key: secretkey\r\n",
      "            name: mlpipeline-minio-artifact\r\n",
      "      parameters:\r\n",
      "      - name: add-fn-2-output\r\n",
      "        valueFrom:\r\n",
      "          path: /outputs/Output/data\r\n",
      "  - dag:\r\n",
      "      tasks:\r\n",
      "      - arguments:\r\n",
      "          parameters:\r\n",
      "          - name: a\r\n",
      "            value: '{{inputs.parameters.a}}'\r\n",
      "        name: add-fn\r\n",
      "        template: add-fn\r\n",
      "      - arguments:\r\n",
      "          parameters:\r\n",
      "          - name: c\r\n",
      "            value: '{{inputs.parameters.c}}'\r\n",
      "          - name: div-fn-quotient\r\n",
      "            value: '{{tasks.div-fn.outputs.parameters.div-fn-quotient}}'\r\n",
      "        dependencies:\r\n",
      "        - div-fn\r\n",
      "        name: add-fn-2\r\n",
      "        template: add-fn-2\r\n",
      "      - arguments:\r\n",
      "          parameters:\r\n",
      "          - name: add-fn-output\r\n",
      "            value: '{{tasks.add-fn.outputs.parameters.add-fn-output}}'\r\n",
      "          - name: b\r\n",
      "            value: '{{inputs.parameters.b}}'\r\n",
      "        dependencies:\r\n",
      "        - add-fn\r\n",
      "        name: div-fn\r\n",
      "        template: div-fn\r\n",
      "    inputs:\r\n",
      "      parameters:\r\n",
      "      - name: a\r\n",
      "      - name: b\r\n",
      "      - name: c\r\n",
      "    name: calculation-pipeline\r\n",
      "  - container:\r\n",
      "      args:\r\n",
      "      - '{{inputs.parameters.add-fn-output}}'\r\n",
      "      - '{{inputs.parameters.b}}'\r\n",
      "      - /\r\n",
      "      - /outputs/quotient/data\r\n",
      "      - /outputs/remainder/data\r\n",
      "      command:\r\n",
      "      - python3\r\n",
      "      - -c\r\n",
      "      - \"from typing import NamedTuple\\n\\ndef div_fn(dividend: float, divisor:float,\\\r\n",
      "        \\ output_dir:str = './') -> NamedTuple('DivOutput', [('quotient', float),\\\r\n",
      "        \\ ('remainder', float)]):\\n    '''Divides two numbers and calculate  the quotient\\\r\n",
      "        \\ and remainder'''\\n    #Imports inside a component function:\\n    import\\\r\n",
      "        \\ numpy as np\\n\\n    #This function demonstrates how to use nested functions\\\r\n",
      "        \\ inside a component function:\\n    def nested_div_helper(dividend, divisor):\\n\\\r\n",
      "        \\        return np.divmod(dividend, divisor)\\n\\n    (quotient, remainder)\\\r\n",
      "        \\ = nested_div_helper(dividend, divisor)\\n\\n    from tensorflow.python.lib.io\\\r\n",
      "        \\ import file_io\\n    import json\\n    \\n    # Exports two sample metrics:\\n\\\r\n",
      "        \\    metrics = {\\n      'metrics': [{\\n          'name': 'quotient',\\n   \\\r\n",
      "        \\       'numberValue':  float(quotient),\\n        },{\\n          'name': 'remainder',\\n\\\r\n",
      "        \\          'numberValue':  float(remainder),\\n        }]}\\n\\n    with file_io.FileIO(output_dir\\\r\n",
      "        \\ + 'mlpipeline-metrics.json', 'w') as f:\\n        json.dump(metrics, f)\\n\\\r\n",
      "        \\n    from collections import namedtuple\\n    output = namedtuple('DivOutput',\\\r\n",
      "        \\ ['quotient', 'remainder'])\\n    return output(quotient, remainder)\\n\\nimport\\\r\n",
      "        \\ sys\\n_args = {\\n    'dividend': float(sys.argv[1]),\\n    'divisor': float(sys.argv[2]),\\n\\\r\n",
      "        \\    'output_dir': str(sys.argv[3]),\\n}\\n_output_files = [\\n    sys.argv[4],\\n\\\r\n",
      "        \\    sys.argv[5],\\n]\\n\\n_outputs = div_fn(**_args)\\n\\nif not hasattr(_outputs,\\\r\n",
      "        \\ '__getitem__') or isinstance(_outputs, str):\\n    _outputs = [_outputs]\\n\\\r\n",
      "        \\nfrom pathlib import Path\\nfor idx, filename in enumerate(_output_files):\\n\\\r\n",
      "        \\    _output_path = Path(filename)\\n    _output_path.parent.mkdir(parents=True,\\\r\n",
      "        \\ exist_ok=True)\\n    _output_path.write_text(str(_outputs[idx]))\\n\"\r\n",
      "      image: tensorflow/tensorflow:1.13.1-py3\r\n",
      "    inputs:\r\n",
      "      parameters:\r\n",
      "      - name: add-fn-output\r\n",
      "      - name: b\r\n",
      "    name: div-fn\r\n",
      "    outputs:\r\n",
      "      artifacts:\r\n",
      "      - name: mlpipeline-ui-metadata\r\n",
      "        path: /mlpipeline-ui-metadata.json\r\n",
      "        s3:\r\n",
      "          accessKeySecret:\r\n",
      "            key: accesskey\r\n",
      "            name: mlpipeline-minio-artifact\r\n",
      "          bucket: mlpipeline\r\n",
      "          endpoint: minio-service.kubeflow:9000\r\n",
      "          insecure: true\r\n",
      "          key: runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-ui-metadata.tgz\r\n",
      "          secretKeySecret:\r\n",
      "            key: secretkey\r\n",
      "            name: mlpipeline-minio-artifact\r\n",
      "      - name: mlpipeline-metrics\r\n",
      "        path: /mlpipeline-metrics.json\r\n",
      "        s3:\r\n",
      "          accessKeySecret:\r\n",
      "            key: accesskey\r\n",
      "            name: mlpipeline-minio-artifact\r\n",
      "          bucket: mlpipeline\r\n",
      "          endpoint: minio-service.kubeflow:9000\r\n",
      "          insecure: true\r\n",
      "          key: runs/{{workflow.uid}}/{{pod.name}}/mlpipeline-metrics.tgz\r\n",
      "          secretKeySecret:\r\n",
      "            key: secretkey\r\n",
      "            name: mlpipeline-minio-artifact\r\n",
      "      parameters:\r\n",
      "      - name: div-fn-quotient\r\n",
      "        valueFrom:\r\n",
      "          path: /outputs/quotient/data\r\n",
      "      - name: div-fn-remainder\r\n",
      "        valueFrom:\r\n",
      "          path: /outputs/remainder/data\r\n"
     ]
    }
   ],
   "source": [
    "!cat pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit the pipeline for execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/4e7e8c4d-ed5a-45d6-9a83-2bad99e1ba8e\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/621ed1d0-cc12-41de-a31e-b43ea6cf67af\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Specify pipeline argument values\n",
    "arguments = {'a': '3', 'b': '11'}\n",
    "\n",
    "#Get or create an experiment and submit a pipeline run\n",
    "import kfp\n",
    "client = kfp.Client()\n",
    "experiment = client.create_experiment('add_div_pipeline')\n",
    "\n",
    "#Submit a pipeline run\n",
    "run_name = pipeline_func.__name__ + ' run'\n",
    "run_result = client.run_pipeline(experiment.id, run_name, pipeline_filename, arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
